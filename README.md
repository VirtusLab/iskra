# Typed Spark

Wrapper around Spark API for Scala 3 which allows writing typesafe and boilerplate-free Spark code without losing all the optimizations Catalyst provides for DataFrames.

## How is this possible?

Spark 3.2.0 is cross-compiled to 2.13, which opens a way to using Spark from Scala 3 code, as Scala 3 projects can depend on Scala 2.13 artifacts.
The only missing element of the jigsaw seems to be deriving implicit instances of Spark's `Encoder` which relies on presence of implicit `TypeTag` instances,
which are no longer generated by Scala 3 compiler and there are no plans to support them.
Luckily there's [spark-scala3](https://github.com/vincenzobaz/spark-scala3/) library, which provides the missing instances of `Encoder` but using the new features of Scala 3 instead of relying on `TypeTag`s. There are still some corner cases that are not handled by the library but hopefully they will be fixed soon.

## Prerequisites

As spark-scala3 is not officially published for Spark 3.2.0 yet, to be able to use it you'll need to clone the repository, slightly modify the build definition and publish the project locally.

* Run `git clone https://github.com/vincenzobaz/spark-scala3.git`
* Replace `val sparkVersion = "3.2.0-SNAPSHOT"` with `val sparkVersion = "3.2.0"`
* Run `sbt 'set ThisBuild/version := "0.1.3-spark3.2.0-SNAPSHOT"; publishLocal'`

## Building and running

This project can be built and run with sbt or [scala-cli](https://scala-cli.virtuslab.org/).
Scala-cli is more lightweight and won't throw `InterruptedException` for successful runs (as opposed to sbt) but currently it's less useful when debugging macros as it swallows the content of stdout produced during macro expansion.